<rss xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" version="2.0"><channel><title><![CDATA[Notes]]></title><description><![CDATA[Obsidian digital garden]]></description><link>http://github.com/dylang/node-rss</link><image><url>site-lib/media/favicon.png</url><title>Notes</title><link/></image><generator>Webpage HTML Export plugin for Obsidian</generator><lastBuildDate>Wed, 25 Feb 2026 00:27:00 GMT</lastBuildDate><atom:link href="site-lib/rss.xml" rel="self" type="application/rss+xml"/><pubDate>Wed, 25 Feb 2026 00:27:00 GMT</pubDate><ttl>60</ttl><dc:creator/><item><title><![CDATA[Index]]></title><description><![CDATA[
Analysis: <a data-href="Numbers" href="analysis/numbers.html" class="original-internal-link" target="_self" rel="noopener nofollow" style="display: none;">Numbers</a><a data-href="Numbers" href="analysis/numbers.html" class="internal-link mathLink-internal-link" target="_self" rel="noopener nofollow">Numbers</a>
<br><a data-href="Sequences" href="analysis/sequences.html" class="original-internal-link" target="_self" rel="noopener nofollow" style="display: none;">Sequences</a><a data-href="Sequences" href="analysis/sequences.html" class="internal-link mathLink-internal-link" target="_self" rel="noopener nofollow">Sequences</a>
<br><a data-href="Continuity" href="analysis/continuity.html" class="original-internal-link" target="_self" rel="noopener nofollow" style="display: none;">Continuity</a><a data-href="Continuity" href="analysis/continuity.html" class="internal-link mathLink-internal-link" target="_self" rel="noopener nofollow">Continuity</a> Differential Equations <br><a data-href="Methods for First Order Differential Equations" href="differential-equations/methods-for-first-order-differential-equations.html" class="original-internal-link" target="_self" rel="noopener nofollow" style="display: none;">Methods for First Order Differential Equations</a><a data-href="Methods for First Order Differential Equations" href="differential-equations/methods-for-first-order-differential-equations.html" class="internal-link mathLink-internal-link" target="_self" rel="noopener nofollow">Methods for First Order Differential Equations</a>
<br><a data-href="Methods for Second Order Differential Equations" href="differential-equations/methods-for-second-order-differential-equations.html" class="original-internal-link" target="_self" rel="noopener nofollow" style="display: none;">Methods for Second Order Differential Equations</a><a data-href="Methods for Second Order Differential Equations" href="differential-equations/methods-for-second-order-differential-equations.html" class="internal-link mathLink-internal-link" target="_self" rel="noopener nofollow">Methods for Second Order Differential Equations</a> DSA <br><a data-href="Sorting" href="dsa/sorting.html" class="original-internal-link" target="_self" rel="noopener nofollow" style="display: none;">Sorting</a><a data-href="Sorting" href="dsa/sorting.html" class="internal-link mathLink-internal-link" target="_self" rel="noopener nofollow">Sorting</a> ]]></description><link>index.html</link><guid isPermaLink="false">Index.md</guid><pubDate>Wed, 25 Feb 2026 00:26:49 GMT</pubDate></item><item><title><![CDATA[Numbers]]></title><description><![CDATA[Definition 1 (Positive Integers).
We denote the set of positive integers by .
Axiom 2 (Peano Axioms). 1 belongs to If , then its successor belongs to 1 is not a successor of any element in If and have the same successor, then A subset of which contains 1 and contains whenever it contains must equal The <a data-href="#^28570a" href="#^28570a" class="original-internal-link" target="_self" rel="noopener nofollow" style="display: none;">^28570a</a><a data-href="#^28570a" href="#^28570a" class="internal-link mathLink-internal-link" target="_self" rel="noopener nofollow">Peano Axioms (Axiom 2)</a> offer a rigorous construction of . It also forms the foundation for mathematical induction.Note that operations like subtraction allow us to escape . We extend our exploration beyond :Definition 3 (Integers).
We define the set of integers to be , where .
Note that is closed under addition, subtraction, and multiplication. Still, we are able to escape through basic arithmetic, namely division. We attempt to fill in this gap:Definition 4 (Rational Numbers).
We define the set of rational numbers to be under the equivalence relation where .
In an equivalence class, there is a unique representative where are coprime and .
We remain unsatisfied as there are still ways we can escape our new set . We define the following to help understand why:Definition 5 (Algebraic Number).
A number is called an algebraic number if it satisfies a polynomial equation where , , and .
Note that not all algebraic numbers are rational (e.g. ). Naturally, we would like to be able to tell when an algebraic number is rational and when it is not.Theorem 6 (Rational Zeros Theorem).
Suppose , and is a solution to Let where and are coprime and . Then, and .
Proof.
We haveso . Since are coprime, we conclude that .Similarly, we haveso .□Corollary 7.
Consider where . Any rational solution is integer.
Proof.<br>
Suppose is a solution, where are coprime and . By the <a data-href="#^d8a847" href="#^d8a847" class="original-internal-link" target="_self" rel="noopener nofollow" style="display: none;">^d8a847</a><a data-href="#^d8a847" href="#^d8a847" class="internal-link mathLink-internal-link" target="_self" rel="noopener nofollow">Rational Zeros Theorem (Theorem 6)</a>, so . Thus, .
□<br>Remark 8.
The <a data-href="#^d8a847" href="#^d8a847" class="original-internal-link" target="_self" rel="noopener nofollow" style="display: none;">^d8a847</a><a data-href="#^d8a847" href="#^d8a847" class="internal-link mathLink-internal-link" target="_self" rel="noopener nofollow">Rational Zeros Theorem (Theorem 6)</a> is incredibly useful for proving that a given algebraic number is irrational. We do so by constructing the polynomial equation that it is a root of and then apply the theorem to show that it has no rational solutions.
Remark 9. and are ordered fields, which give them very nice properties.
We examine some basic properties of .Definition 10 (Absolute Value).
We define if and if .
Definition 11.
For numbers and , we define .
The absolute value has some useful properties, including for all <br>The <a data-href="#^28152a" href="#^28152a" class="original-internal-link" target="_self" rel="noopener nofollow" style="display: none;">^28152a</a><a data-href="#^28152a" href="#^28152a" class="internal-link mathLink-internal-link" target="_self" rel="noopener nofollow">^28152a</a> Theorem 12 (Triangle Inequality).
For all , we have and We define some concepts to help examine the structure of a set.Definition 13 (Maximum and Minimum).
Let be a nonempty subset of . if and for all . if and for all . Remark 14.
If is finite, and are guaranteed to exist.
Definition 15 (Upper and Lower Bound).
Let be a nonempty subset of . If such that for all , is an upper bound of , and is bounded above.
If such that for all , is an lower bound of , and is bounded below.
If is bounded above and bounded below, it is bounded. Definition 16 (Supremum and Infimum).
Let be a nonempty subset of . The supremum of , , is the least upper bound of if it exists.
The infimum of , , is the least greatest bound of if it exists. Now we are ready to discuss the Completeness Axiom.Axiom 17 (Completeness Axiom).
Every nonempty subset that is bounded above has a least upper bound.
Theorem 18 (Archimedian Property).
If and , then for some positive , we have .
Proof.<br>
Suppose for contradiction that there exist and such that for all . This means that the set is bounded above by . By the <a data-href="#^02907a" href="#^02907a" class="original-internal-link" target="_self" rel="noopener nofollow" style="display: none;">^02907a</a><a data-href="#^02907a" href="#^02907a" class="internal-link mathLink-internal-link" target="_self" rel="noopener nofollow">Completeness Axiom (Axiom 17)</a>, it follows that exists. Since is the least upper bound, is not an upper bound, so there exists such that . Rearranging, we have , so is not an upper bound. This is a contradiction.
□Theorem 19 (Denseness of ).
If and , then there exists such that .
Proof.
We want to show that there exist such that or<br>Since , the <a data-href="#^379052" href="#^379052" class="original-internal-link" target="_self" rel="noopener nofollow" style="display: none;">^379052</a><a data-href="#^379052" href="#^379052" class="internal-link mathLink-internal-link" target="_self" rel="noopener nofollow">Archimedian Property (Theorem 18)</a> ensures that there exists such that Now we must show that there exists an such that . Note that there exists such that .
Consider the set , which contains the integers bounded by . Also, consider the set . Note that these sets are finite and nonempty (since they contain )
□]]></description><link>analysis/numbers.html</link><guid isPermaLink="false">Analysis/Numbers.md</guid><pubDate>Tue, 24 Feb 2026 21:39:31 GMT</pubDate></item><item><title><![CDATA[Sequences]]></title><description><![CDATA[Definition 1 (Monotonic).
A sequence is called decreasing if and increasing if for all . A sequence that is increasing or decreasing is monotonic.
Theorem 2.
All bounded monotone sequences converge
Proof.
Without loss of generality, assume is increasing. Let . Observe that for all , cannot be an upper bound, so there exists such that . Since is increasing, for all . It follows that for all , so .
□Theorem 3.
If is unbounded and increasing, then Proof.
Let . Since is unbounded, there exists such that . Since is increasing, for all .
□Definition 4 ( and ).
Let be a sequence and denote and . We define and as follows: This offers a new perspective from which to understand convergence. We no longer require that we know what the sequence converges to ahead of time to test its convergence.Theorem 5. exists if and only if .
Proof.
Assume exists
We consider two cases:
Case 1: .
Suppose and let be a positive integer. Then, there exists a positive integer such that for all , . Note that so . Similar logic holds for the case.Case 2: is finite.
Our goal is to bound and and squeeze them onto .
Suppose where is a real number and let . We know that there must exist such that for all . We can rewrite this as for all , soThus, for all , we have . Taking and applying the definition of , we have . Since can be arbitrarily small, we have shown that . Applying the same logic to and bounding it below by , we can show that , from which we conclude that as can be arbitrarily small.Because and we have shown that , we conclude that .Assume We seek to prove the existence of exists. Once again, we consider two cases:
Case 1: .
This case is quite obvious. Suppose . This means that for all , there exists some such that . Since for all , it follows that for all . By definition, we have . We can apply the same logic using and the .Case 2: are finite.
Suppose , where . We seek to prove that . Let . Like in the other direction, we will do this by bounding around mk. Since , there exists a positive integer such that ^058ff7
This means that , which implies for all . Similarly, since , there exists a positive integer such that which means or for all . Together, we have for all . Therefore, .
□Definition 6 (Cauchy Sequence).
A sequence of real numbers is Cauchy if for all , there exists such that for any , we have .
This gives an alternative, yet (as we will show) equivalent, perspective to study the convergence of sequences without knowing what a sequence converges to ahead of time.Lemma 7 (Convergent sequences are Cauchy.).Proof.
Let and suppose converges to . By definition, there exist such that for all , Note that . Hence, is Cauchy.
□Lemma 8 (Cauchy sequences are bounded.).Proof.
Suppose is Cauchy. This means that there exists an such that for all , we have . Since , we can fix , giving for all . Since , it follows that for all , so we can bound all the terms after . Since is a finite number, we can bound all the terms before by . Hence, all of the terms in the sequence can be bounded by .
□Theorem 9.
A sequence is convergent if and only if it is Cauchy
Proof.
Conveniently, we have already shown in a Lemma that convergent sequences are Cauchy. We now prove that Cauchy sequences are convergent.Suppose is a Cauchy sequence. This means that for all , there exists such that for all , we have . We rewrite this asTaking , we find that . But we know that . Thus, we have shown that , so converges.
□Remark 10.
The Completeness Axiom plays an important role in this proof, as it assures us that and are meaningful here.
Definition 11 (Subsequence).
Suppose is a sequence. Given a sequence in , denoted as , is subsequence of .
The following theorem is particularly useful in proving the existence of a subsequence if its limit is known.Theorem 12.
For all , there exists a monotonic subsequence of converging to if and only if the set is infinite for all .
Proof.
The forward direction is fairly obvious and follows from the definition of convergence. We construct a subsequence as follows. Pick any . Let . Since is infinite for all , the set is infinite. We define the th element of our constructed sequence as such that and . Note that the latter condition (which ensures that we construct a valid subsequence) can always be satisfied since we have infinitely many choices and only finitely many invalid choices.
\ref{}<a data-tooltip-position="top" aria-label="Sequences &gt; Theorem Every sequence $(s_{n})$ has a monotone subsequence." data-href="Sequences#Theorem Every sequence $(s_{n})$ has a monotone subsequence." href="analysis/sequences.html#Theorem Every sequence $(s_{n})$ has a monotone subsequence." class="original-internal-link" target="_self" rel="noopener nofollow" style="display: none;">We can select a monotonic subsequence</a><a data-tooltip-position="top" aria-label="Sequences &gt; Theorem Every sequence $(s_{n})$ has a monotone subsequence." data-href="Sequences#Theorem Every sequence $(s_{n})$ has a monotone subsequence." href="analysis/sequences.html#Theorem Every sequence $(s_{n})$ has a monotone subsequence." class="internal-link mathLink-internal-link" target="_self" rel="noopener nofollow">We can select a monotonic subsequence</a>. Without loss of generality, suppose is selected to be monotonic.We must now show that actually converges to . By the Archimedean property, we know that for all , there exists such that . Let . Then, for all , we have .
□Theorem 13.
If a sequence is unbounded above/below, it has a subsequence with limit .
Proof.
Observe that if and the sequence is unbounded, we can easily construct a subsequence with limit by repeatedly choosing more extreme values, which are guaranteed to exist due to the sequence being unbounded.
□Remark 14.
An interesting related result is that all real numbers can be expressed as the limit of some subsequence of the rationals.
Theorem 15.
If converges, then every subsequence converges to the same limit.
Proof.
Let and . Since converges, there exists such that for all , . Let be a subsequence of . We observe that for all , which is easily proved via induction. Take such that . It follows that for all , we have , so . Thus, .
□Theorem 16.
Every sequence has a monotone subsequence.
Proof.
We define to be dominant if for all . Consider the following cases:Case 1: There are infinitely many dominant terms.
Let be a dominant term. Since , we have . Thus, we can easily construct a decreasing subsequence.Case 2: There are finitely many dominant terms.
There exists such that is not dominant for all . Pick . It follows that is not dominant, so there exists such that . We know that is not dominant as . We repeat this process to form an increasing subsequence.
Hence, we can always construct a monotone subsequence.
□Theorem 17 (Bolzano-Weierstrass).
Every bounded sequence has a convergent subsequence.
Proof.<br>
We have shown that <a data-tooltip-position="top" aria-label="Sequences &gt; Theorem (Bolzano-Weierstrass) Every bounded sequence has a convergent subsequence." data-href="Sequences#Theorem (Bolzano-Weierstrass) Every bounded sequence has a convergent subsequence." href="analysis/sequences.html#Theorem (Bolzano-Weierstrass) Every bounded sequence has a convergent subsequence." class="original-internal-link" target="_self" rel="noopener nofollow" style="display: none;">every sequence has a monotone subsequence</a><a data-tooltip-position="top" aria-label="Sequences &gt; Theorem (Bolzano-Weierstrass) Every bounded sequence has a convergent subsequence." data-href="Sequences#Theorem (Bolzano-Weierstrass) Every bounded sequence has a convergent subsequence." href="analysis/sequences.html#Theorem (Bolzano-Weierstrass) Every bounded sequence has a convergent subsequence." class="internal-link mathLink-internal-link" target="_self" rel="noopener nofollow">every sequence has a monotone subsequence</a>. If we have a bounded sequence, it must also have a bounded monotone subsequence, which <a data-tooltip-position="top" aria-label="Sequences &gt; Theorem All bounded monotone sequences converge." data-href="Sequences#Theorem All bounded monotone sequences converge." href="analysis/sequences.html#Theorem All bounded monotone sequences converge." class="original-internal-link" target="_self" rel="noopener nofollow" style="display: none;">we have shown to converge</a><a data-tooltip-position="top" aria-label="Sequences &gt; Theorem All bounded monotone sequences converge." data-href="Sequences#Theorem All bounded monotone sequences converge." href="analysis/sequences.html#Theorem All bounded monotone sequences converge." class="internal-link mathLink-internal-link" target="_self" rel="noopener nofollow">we have shown to converge</a>.
There is another less elegant proof involving interval division resulting in a Cauchy sequence.
□Remark 18.
Interestingly, several of the statements we have proved are equivalent to the Completeness Axiom. In particular, the following are equivalent: Completeness of <br><a data-tooltip-position="top" aria-label="Sequences &gt; Theorem A sequence is convergent if and only if it is Cauchy" data-href="Sequences#Theorem A sequence is convergent if and only if it is Cauchy" href="analysis/sequences.html#Theorem A sequence is convergent if and only if it is Cauchy" class="original-internal-link" target="_self" rel="noopener nofollow" style="display: none;">Cauchy sequences converge</a><a data-tooltip-position="top" aria-label="Sequences &gt; Theorem A sequence is convergent if and only if it is Cauchy" data-href="Sequences#Theorem A sequence is convergent if and only if it is Cauchy" href="analysis/sequences.html#Theorem A sequence is convergent if and only if it is Cauchy" class="internal-link mathLink-internal-link" target="_self" rel="noopener nofollow">Cauchy sequences converge</a>
<br><a data-tooltip-position="top" aria-label="Sequences &gt; Theorem All bounded monotone sequences converge." data-href="Sequences#Theorem All bounded monotone sequences converge." href="analysis/sequences.html#Theorem All bounded monotone sequences converge." class="original-internal-link" target="_self" rel="noopener nofollow" style="display: none;">Bounded monotonic sequences converge</a><a data-tooltip-position="top" aria-label="Sequences &gt; Theorem All bounded monotone sequences converge." data-href="Sequences#Theorem All bounded monotone sequences converge." href="analysis/sequences.html#Theorem All bounded monotone sequences converge." class="internal-link mathLink-internal-link" target="_self" rel="noopener nofollow">Bounded monotonic sequences converge</a>
<br><a data-tooltip-position="top" aria-label="Sequences &gt; Theorem (Bolzano-Weierstrass) Every bounded sequence has a convergent subsequence." data-href="Sequences#Theorem (Bolzano-Weierstrass) Every bounded sequence has a convergent subsequence." href="analysis/sequences.html#Theorem (Bolzano-Weierstrass) Every bounded sequence has a convergent subsequence." class="original-internal-link" target="_self" rel="noopener nofollow" style="display: none;">Bolzano-Weierstrass Theorem</a><a data-tooltip-position="top" aria-label="Sequences &gt; Theorem (Bolzano-Weierstrass) Every bounded sequence has a convergent subsequence." data-href="Sequences#Theorem (Bolzano-Weierstrass) Every bounded sequence has a convergent subsequence." href="analysis/sequences.html#Theorem (Bolzano-Weierstrass) Every bounded sequence has a convergent subsequence." class="internal-link mathLink-internal-link" target="_self" rel="noopener nofollow">Bolzano-Weierstrass Theorem</a> Definition 19 (Subsequential Limit).
Let be a sequence in . A subsequential limit is any real number or symbol or that is the limit of some subsequence of .
Theorem 20.
Let be a sequence. There exists a monotone subsequence whose limit is and a monotone subsequence whose limit is .
Proof.<br>
<a data-tooltip-position="top" aria-label="Sequences &gt; Theorem If a sequence is unbounded above/below, it has a subsequence with limit $+/- infty$." data-href="Sequences#Theorem If a sequence is unbounded above/below, it has a subsequence with limit $+/- infty$." href="analysis/sequences.html#Theorem If a sequence is unbounded above/below, it has a subsequence with limit $+/- infty$." class="original-internal-link" target="_self" rel="noopener nofollow" style="display: none;">We have shown</a><a data-tooltip-position="top" aria-label="Sequences &gt; Theorem If a sequence is unbounded above/below, it has a subsequence with limit $+/- infty$." data-href="Sequences#Theorem If a sequence is unbounded above/below, it has a subsequence with limit $+/- infty$." href="analysis/sequences.html#Theorem If a sequence is unbounded above/below, it has a subsequence with limit $+/- infty$." class="internal-link mathLink-internal-link" target="_self" rel="noopener nofollow">We have shown</a> that if is unbounded, then there exists a subsequence whose limit is . Assume that is bounded. We have . Using our <a data-tooltip-position="top" aria-label="Sequences &gt; $ limsup$ and $ liminf$" data-href="Sequences#$ limsup$ and $ liminf$" href="analysis/sequences.html#$ limsup$ and $ liminf$" class="original-internal-link" target="_self" rel="noopener nofollow" style="display: none;">notation</a><a data-tooltip-position="top" aria-label="Sequences &gt; $ limsup$ and $ liminf$" data-href="Sequences#$ limsup$ and $ liminf$" href="analysis/sequences.html#$ limsup$ and $ liminf$" class="internal-link mathLink-internal-link" target="_self" rel="noopener nofollow">notation</a>, we have Let . From the limit, we know that there exists such that for all , or Suppose for contradiction that holds for only finitely many . Then, there exists such that for all , . This implies two possibilities:
Suppose . This implies , which is a contradiction of . Suppose . This implies , which is a contradiction of .<br>
Hence, the is infinite. <a data-tooltip-position="top" aria-label="Sequences &gt; Theorem For all $t in mathbb{R}$, there exists a subsequence of $(s_{n})$ converging to $t$ if and only if the set $ { n in mathbb{N} s_{n}-t &lt; epsilon }$ is infinite for all $ epsilon&gt;0$." data-href="Sequences#Theorem For all $t in mathbb{R}$, there exists a subsequence of $(s_{n})$ converging to $t$ if and only if the set $ { n in mathbb{N} s_{n}-t &lt; epsilon }$ is infinite for all $ epsilon&gt;0$." href="analysis/sequences.html#Theorem For all $t in mathbb{R}$, there exists a subsequence of $(s_{n})$ converging to $t$ if and only if the set $ { n in mathbb{N} s_{n}-t &lt; epsilon }$ is infinite for all $ epsilon&gt;0$." class="original-internal-link" target="_self" rel="noopener nofollow" style="display: none;">It follows</a><a data-tooltip-position="top" aria-label="Sequences &gt; Theorem For all $t in mathbb{R}$, there exists a subsequence of $(s_{n})$ converging to $t$ if and only if the set $ { n in mathbb{N} s_{n}-t &lt; epsilon }$ is infinite for all $ epsilon&gt;0$." data-href="Sequences#Theorem For all $t in mathbb{R}$, there exists a subsequence of $(s_{n})$ converging to $t$ if and only if the set $ { n in mathbb{N} s_{n}-t &lt; epsilon }$ is infinite for all $ epsilon&gt;0$." href="analysis/sequences.html#Theorem For all $t in mathbb{R}$, there exists a subsequence of $(s_{n})$ converging to $t$ if and only if the set $ { n in mathbb{N} s_{n}-t &lt; epsilon }$ is infinite for all $ epsilon&gt;0$." class="internal-link mathLink-internal-link" target="_self" rel="noopener nofollow">It follows</a> that there exists a <a data-tooltip-position="top" aria-label="Sequences &gt; Theorem Every sequence $(s_{n})$ has a monotone subsequence." data-href="Sequences#Theorem Every sequence $(s_{n})$ has a monotone subsequence." href="analysis/sequences.html#Theorem Every sequence $(s_{n})$ has a monotone subsequence." class="original-internal-link" target="_self" rel="noopener nofollow" style="display: none;">monotonic</a><a data-tooltip-position="top" aria-label="Sequences &gt; Theorem Every sequence $(s_{n})$ has a monotone subsequence." data-href="Sequences#Theorem Every sequence $(s_{n})$ has a monotone subsequence." href="analysis/sequences.html#Theorem Every sequence $(s_{n})$ has a monotone subsequence." class="internal-link mathLink-internal-link" target="_self" rel="noopener nofollow">monotonic</a> subsequence that converges to .
A similar proof holds for .
□
Theorem 21.
Let be any sequence in and let denote the set of subsequential limits of . Then, (i) is nonempty.
(ii) and .
(iii) exists if and only if has exactly one element. Proof.<br>
(i) follows from <a data-tooltip-position="top" aria-label="Sequences &gt; Theorem Let $(s_{n})$ be a sequence. There exists a monotone subsequence whose limit is $ limsup s_{n}$ and a monotone subsequence whose limit is $ liminf s_{n}$." data-href="Sequences#Theorem Let $(s_{n})$ be a sequence. There exists a monotone subsequence whose limit is $ limsup s_{n}$ and a monotone subsequence whose limit is $ liminf s_{n}$." href="analysis/sequences.html#Theorem Let $(s_{n})$ be a sequence. There exists a monotone subsequence whose limit is $ limsup s_{n}$ and a monotone subsequence whose limit is $ liminf s_{n}$." class="original-internal-link" target="_self" rel="noopener nofollow" style="display: none;">the fact</a><a data-tooltip-position="top" aria-label="Sequences &gt; Theorem Let $(s_{n})$ be a sequence. There exists a monotone subsequence whose limit is $ limsup s_{n}$ and a monotone subsequence whose limit is $ liminf s_{n}$." data-href="Sequences#Theorem Let $(s_{n})$ be a sequence. There exists a monotone subsequence whose limit is $ limsup s_{n}$ and a monotone subsequence whose limit is $ liminf s_{n}$." href="analysis/sequences.html#Theorem Let $(s_{n})$ be a sequence. There exists a monotone subsequence whose limit is $ limsup s_{n}$ and a monotone subsequence whose limit is $ liminf s_{n}$." class="internal-link mathLink-internal-link" target="_self" rel="noopener nofollow">the fact</a> that there exist subsequences with limit and , which are guaranteed to exist. <br>We now prove (ii). Suppose is unbounded from above. <a data-tooltip-position="top" aria-label="Sequences &gt; Theorem If a sequence is unbounded above/below, it has a subsequence with limit $+/- infty$." data-href="Sequences#Theorem If a sequence is unbounded above/below, it has a subsequence with limit $+/- infty$." href="analysis/sequences.html#Theorem If a sequence is unbounded above/below, it has a subsequence with limit $+/- infty$." class="original-internal-link" target="_self" rel="noopener nofollow" style="display: none;">Then</a><a data-tooltip-position="top" aria-label="Sequences &gt; Theorem If a sequence is unbounded above/below, it has a subsequence with limit $+/- infty$." data-href="Sequences#Theorem If a sequence is unbounded above/below, it has a subsequence with limit $+/- infty$." href="analysis/sequences.html#Theorem If a sequence is unbounded above/below, it has a subsequence with limit $+/- infty$." class="internal-link mathLink-internal-link" target="_self" rel="noopener nofollow">Then</a>, there exists a subsequence such that , so . A similar proof holds for sequences unbounded from below regarding and .<br>
Now, assume is bounded. Take and assume . <a data-tooltip-position="top" aria-label="Sequences &gt; Theorem $ lim_{ n to infty }s_{n}$ exists if and only if $ limsup s_{n} = liminf s_{n} = lim_{ n to infty }s_{n}$." data-href="Sequences#Theorem $ lim_{ n to infty }s_{n}$ exists if and only if $ limsup s_{n} = liminf s_{n} = lim_{ n to infty }s_{n}$." href="analysis/sequences.html#Theorem $ lim_{ n to infty }s_{n}$ exists if and only if $ limsup s_{n} = liminf s_{n} = lim_{ n to infty }s_{n}$." class="original-internal-link" target="_self" rel="noopener nofollow" style="display: none;">Then</a><a data-tooltip-position="top" aria-label="Sequences &gt; Theorem $ lim_{ n to infty }s_{n}$ exists if and only if $ limsup s_{n} = liminf s_{n} = lim_{ n to infty }s_{n}$." data-href="Sequences#Theorem $ lim_{ n to infty }s_{n}$ exists if and only if $ limsup s_{n} = liminf s_{n} = lim_{ n to infty }s_{n}$." href="analysis/sequences.html#Theorem $ lim_{ n to infty }s_{n}$ exists if and only if $ limsup s_{n} = liminf s_{n} = lim_{ n to infty }s_{n}$." class="internal-link mathLink-internal-link" target="_self" rel="noopener nofollow">Then</a>, , where the subscript appended to and indicate that their limits are taken with respect to . Note that for all . We haveSince can be any element in , we have<br>We have <a data-tooltip-position="top" aria-label="Sequences &gt; Theorem Let $(s_{n})$ be a sequence. There exists a monotone subsequence whose limit is $ limsup s_{n}$ and a monotone subsequence whose limit is $ liminf s_{n}$." data-href="Sequences#Theorem Let $(s_{n})$ be a sequence. There exists a monotone subsequence whose limit is $ limsup s_{n}$ and a monotone subsequence whose limit is $ liminf s_{n}$." href="analysis/sequences.html#Theorem Let $(s_{n})$ be a sequence. There exists a monotone subsequence whose limit is $ limsup s_{n}$ and a monotone subsequence whose limit is $ liminf s_{n}$." class="original-internal-link" target="_self" rel="noopener nofollow" style="display: none;">proved</a><a data-tooltip-position="top" aria-label="Sequences &gt; Theorem Let $(s_{n})$ be a sequence. There exists a monotone subsequence whose limit is $ limsup s_{n}$ and a monotone subsequence whose limit is $ liminf s_{n}$." data-href="Sequences#Theorem Let $(s_{n})$ be a sequence. There exists a monotone subsequence whose limit is $ limsup s_{n}$ and a monotone subsequence whose limit is $ liminf s_{n}$." href="analysis/sequences.html#Theorem Let $(s_{n})$ be a sequence. There exists a monotone subsequence whose limit is $ limsup s_{n}$ and a monotone subsequence whose limit is $ liminf s_{n}$." class="internal-link mathLink-internal-link" target="_self" rel="noopener nofollow">proved</a> that previously. Thus, and . Therefore, and .<br>Part (iii) is simply a <a data-tooltip-position="top" aria-label="Sequences &gt; Theorem $ lim_{ n to infty }s_{n}$ exists if and only if $ limsup s_{n} = liminf s_{n} = lim_{ n to infty }s_{n}$." data-href="Sequences#Theorem $ lim_{ n to infty }s_{n}$ exists if and only if $ limsup s_{n} = liminf s_{n} = lim_{ n to infty }s_{n}$." href="analysis/sequences.html#Theorem $ lim_{ n to infty }s_{n}$ exists if and only if $ limsup s_{n} = liminf s_{n} = lim_{ n to infty }s_{n}$." class="original-internal-link" target="_self" rel="noopener nofollow" style="display: none;">restatement</a><a data-tooltip-position="top" aria-label="Sequences &gt; Theorem $ lim_{ n to infty }s_{n}$ exists if and only if $ limsup s_{n} = liminf s_{n} = lim_{ n to infty }s_{n}$." data-href="Sequences#Theorem $ lim_{ n to infty }s_{n}$ exists if and only if $ limsup s_{n} = liminf s_{n} = lim_{ n to infty }s_{n}$." href="analysis/sequences.html#Theorem $ lim_{ n to infty }s_{n}$ exists if and only if $ limsup s_{n} = liminf s_{n} = lim_{ n to infty }s_{n}$." class="internal-link mathLink-internal-link" target="_self" rel="noopener nofollow">restatement</a>.
□Theorem 22.
Suppose is a sequence in and . Then, .
Remark 23.
This result shows that is closed, but is not particularly interesting. Its proof is left as an exercise for the overly-motivated reader.
Remark 24 (Recall).
Let be a sequence and denote and . We define and as follows: Theorem 25.
If converges to a positive number and is any sequence, then .
Proof.
We first seek to showWe have 3 cases:Case 1: is finite.<br>
We have <a data-tooltip-position="top" aria-label="Sequences &gt; Theorem Let $(s_{n})$ be a sequence. There exists a monotone subsequence whose limit is $ limsup s_{n}$ and a monotone subsequence whose limit is $ liminf s_{n}$." data-href="Sequences#Theorem Let $(s_{n})$ be a sequence. There exists a monotone subsequence whose limit is $ limsup s_{n}$ and a monotone subsequence whose limit is $ liminf s_{n}$." href="analysis/sequences.html#Theorem Let $(s_{n})$ be a sequence. There exists a monotone subsequence whose limit is $ limsup s_{n}$ and a monotone subsequence whose limit is $ liminf s_{n}$." class="original-internal-link" target="_self" rel="noopener nofollow" style="display: none;">shown</a><a data-tooltip-position="top" aria-label="Sequences &gt; Theorem Let $(s_{n})$ be a sequence. There exists a monotone subsequence whose limit is $ limsup s_{n}$ and a monotone subsequence whose limit is $ liminf s_{n}$." data-href="Sequences#Theorem Let $(s_{n})$ be a sequence. There exists a monotone subsequence whose limit is $ limsup s_{n}$ and a monotone subsequence whose limit is $ liminf s_{n}$." href="analysis/sequences.html#Theorem Let $(s_{n})$ be a sequence. There exists a monotone subsequence whose limit is $ limsup s_{n}$ and a monotone subsequence whose limit is $ liminf s_{n}$." class="internal-link mathLink-internal-link" target="_self" rel="noopener nofollow">shown</a> that there must exist a subsequence such that . Furthermore, since all subsequences of a convergent sequence have the same limit, we <a data-tooltip-position="top" aria-label="Sequences &gt; Theorem If $(s_{n})$ converges, then every subsequence converges to the same limit." data-href="Sequences#Theorem If $(s_{n})$ converges, then every subsequence converges to the same limit." href="analysis/sequences.html#Theorem If $(s_{n})$ converges, then every subsequence converges to the same limit." class="original-internal-link" target="_self" rel="noopener nofollow" style="display: none;">have</a><a data-tooltip-position="top" aria-label="Sequences &gt; Theorem If $(s_{n})$ converges, then every subsequence converges to the same limit." data-href="Sequences#Theorem If $(s_{n})$ converges, then every subsequence converges to the same limit." href="analysis/sequences.html#Theorem If $(s_{n})$ converges, then every subsequence converges to the same limit." class="internal-link mathLink-internal-link" target="_self" rel="noopener nofollow">have</a> , so . Since is the largest possible limit of a sequence , it follows that . Case 2: .<br>
Since is unbounded, <a data-tooltip-position="top" aria-label="Sequences &gt; Theorem If a sequence is unbounded above/below, it has a subsequence with limit $+/- infty$." data-href="Sequences# Theorem If a sequence is unbounded above/below, it has a subsequence with limit $+/- infty$." href="analysis/sequences.html# Theorem If a sequence is unbounded above/below, it has a subsequence with limit $+/- infty$." class="original-internal-link" target="_self" rel="noopener nofollow" style="display: none;">there exists</a><a data-tooltip-position="top" aria-label="Sequences &gt; Theorem If a sequence is unbounded above/below, it has a subsequence with limit $+/- infty$." data-href="Sequences# Theorem If a sequence is unbounded above/below, it has a subsequence with limit $+/- infty$." href="analysis/sequences.html# Theorem If a sequence is unbounded above/below, it has a subsequence with limit $+/- infty$." class="internal-link mathLink-internal-link" target="_self" rel="noopener nofollow">there exists</a> a subsequence of such that . Since , . Hence, .Case 3: .
Since , . Clearly, .Thus, in all cases. Note that for finitely many terms as exists (otherwise we would have a subsequential limit of , which implies or the limit doesn't exist), so we can omit these finite terms. Noting that , we replace with and with in the inequality we just proved, givingyieldingHence, .
□Remark 26 (Useful facts). If , then for every , the set is finite.
If , then for every , the set is infinite.
The set can be infinite. For example, take . Definition 27 (Series). is a partial sum of . We say that the infinite series converges if the sequence of partial sums converges to a real number . A series that does not converge is said to diverge.
Definition 28 (Absolute and Conditional Convergence).
A series is said to be absolutely convergent if converges. Otherwise, it is conditionally convergent. Definition 29 (Cauchy Criterion).
A series satisfies the Cauchy criterion if its sequence of partial sums is a Cauchy sequence. Equivalently, for all , there must exist such that for all Theorem 30.
A series converges if and only if it satisfies the Cauchy criterion.
Theorem 31.
If converges, .
Proof.
Take in the Cauchy criterion.
□Theorem 32 (Ratio Test).
A series of nonzero terms converges absolutely if diverges if otherwise, no useful information is acquired ]]></description><link>analysis/sequences.html</link><guid isPermaLink="false">Analysis/Sequences.md</guid><pubDate>Tue, 24 Feb 2026 19:39:56 GMT</pubDate></item><item><title><![CDATA[Continuity]]></title><description><![CDATA[Definition 1 ( and ).
The set on which a function is defined is . The set of values of is .
Definition 2 (Continuous Function).
We say is continuous at a point if , such that , Definition 3 (Continuous Function (Alternative)).
A function is continuous at if for every sequence such that , we have .
Conversely, is not continuous if there exists a sequence such that but does not converge.
Example 4.
Show at is continuous.
Choose . For all , we have . Then, .]]></description><link>analysis/continuity.html</link><guid isPermaLink="false">Analysis/Continuity.md</guid><pubDate>Tue, 24 Feb 2026 17:18:33 GMT</pubDate></item><item><title><![CDATA[Sorting]]></title><description><![CDATA[Advantages:
Stable
Advantages:
Stable
Advantages:
Disadvantages:
Unstable
Advantages:
Worst case is In-place with extra memory
Disadvantages:
Many cache misses
Unstable
Counts number of a finite set of items and places them accordingly.
Count each category
Calculate start indices
Copy to each element to correct region, incrementing indices
This is a stable sort.Advantages:
Average time is Efficient memory/cache use! Better than <a data-tooltip-position="top" aria-label="Sorting &gt; Heapsort" data-href="Sorting#Heapsort" href="dsa/sorting.html#Heapsort_0" class="original-internal-link" target="_self" rel="noopener nofollow" style="display: none;">Heapsort</a><a data-tooltip-position="top" aria-label="Sorting &gt; Heapsort" data-href="Sorting#Heapsort" href="dsa/sorting.html#Heapsort_0" class="internal-link mathLink-internal-link" target="_self" rel="noopener nofollow">Heapsort</a>
Disadvantages: Worst case time is Unstable Making Quicksort stable makes it less competitive Partitioning is fragile Performance is very dependent on pivot choice Divide and Conquer approach:
Base case: Arrays of length 0 and 1 are already sorted
Inductive step: Guess an pivot to partition the array Last element, middle element, median of 3 Place all elements less than to its left and all elements greater than to its right Initialize left pointer to front and right pointer to end
Walk forwards and backwards until and such that and do not cross Swap and Repeat until and collide Swap to the correct location
Recursively sort elements to the left and to the right of Use tail recursion on the larger side
Note that this sort is unstable. Ideally, we would guess to be the median. This would evenly divide the array so that the left and right arrays to are equally sized. However, this is not feasible, so we randomly pick (usually the last element). Note that this algorithm is on sorted arrays. A better partition algorithm is as follows:
Pick middle value or median of 3 elements (better)
Swap with last element
Pivot is set to last element This simplifies the implementation as the pivot is guaranteed to stay in place during the sorting process Worst case (Pivot is always an extreme): Best case (Pivot divides equally): Average case: Requires one non-tail recursive call and one tail recursive call. Depends on pivot choice.
Without tail recursion optimization and pivot is bad: or Worst case: Sorting algorithm called over each region of an array depends on certain characteristics
<br>If array is small, use <a data-tooltip-position="top" aria-label="Sorting &gt; Insertion" data-href="Sorting#Insertion" href="dsa/sorting.html#Insertion_0" class="original-internal-link" target="_self" rel="noopener nofollow" style="display: none;">Insertion sort</a><a data-tooltip-position="top" aria-label="Sorting &gt; Insertion" data-href="Sorting#Insertion" href="dsa/sorting.html#Insertion_0" class="internal-link mathLink-internal-link" target="_self" rel="noopener nofollow">Insertion sort</a>
<br>If Quicksort is recursing too deeply, use <a data-tooltip-position="top" aria-label="Sorting &gt; Heapsort" data-href="Sorting#Heapsort" href="dsa/sorting.html#Heapsort_0" class="original-internal-link" target="_self" rel="noopener nofollow" style="display: none;">Heapsort</a><a data-tooltip-position="top" aria-label="Sorting &gt; Heapsort" data-href="Sorting#Heapsort" href="dsa/sorting.html#Heapsort_0" class="internal-link mathLink-internal-link" target="_self" rel="noopener nofollow">Heapsort</a> This means we are picking bad pivots <br>Otherwise, use <a data-tooltip-position="top" aria-label="Sorting &gt; Quicksort" data-href="Sorting#Quicksort" href="dsa/sorting.html#Quicksort_0" class="original-internal-link" target="_self" rel="noopener nofollow" style="display: none;">Quicksort</a><a data-tooltip-position="top" aria-label="Sorting &gt; Quicksort" data-href="Sorting#Quicksort" href="dsa/sorting.html#Quicksort_0" class="internal-link mathLink-internal-link" target="_self" rel="noopener nofollow">Quicksort</a>
"Conquer and combine". Very similar to Quicksort.
Sort left half, sort right half, merge.
Designed for external sorting.
Advantages
Stable Use when merging to ensure stable sorting.
Disadvantages Never better than Requires additional memory, unlike Quicksort which is in-place Also copies around data Generally slower than Quicksort
Out of place merge requires additional memory for merging. We can write an algorithm to merge in-place, but we sacrifice stability and performance. Base case: 0 or 1 items Compute middle ()
Sort left half
Sort right half
Merge left and right
Begin with base cases and merge segments until entire array is sorted.
Always (worst, best, average) Safe for recursion, recursive depth grows slowly
Requires additional memory
]]></description><link>dsa/sorting.html</link><guid isPermaLink="false">DSA/Sorting.md</guid><pubDate>Thu, 19 Feb 2026 19:35:31 GMT</pubDate></item><item><title><![CDATA[Methods for Second Order Differential Equations]]></title><description><![CDATA[Consider a second-order differential equation of the formDefinition 1 (Linear Differential Equation).
A second-order differential equation is linear if has the form . This requires that is linear in and . Then, we can rewrite the equation as
If , the equation is homogeneous.
For the purpose of notation, we introduce the differential operator:Definition 2 (Differential Operator Notation).
Let and be continuous functions on an open interval . We define the differential operator for a twice-differentiable function on as We begin our exploration of second-order linear differential equations by considering the case when . First, consider the case when and are constant. Then,We exploit the properties of by substituting it for :Since is nonzero, we conclude that . This is known as the characteristic equation of this differential equation. We conclude that solutions to the differential equation can be expressed as , where is a root of its characteristic equation.If we have only real roots ( and , distinct), our general solution is .
If we have complex roots () and require real solutions, we apply Euler's Formula to arrive at .If we are given a solution , we can find the other solution . We set and substitute into our differential equation. Rearranging, we find that which is a first-order differential equation on . This method tells us that when we have repeated roots, we multiply the second solution by . Intuitively, we restore a degree of freedom that would otherwise be destroyed by the repeated roots, ensuring that we cover all possible solutions with our general solution.What do we do when ?We can write the general solution as , where is the general solution to the corresponding homogeneous equation. This part has no effect on the overall equation as they evaluate to zero when the differential operator is applied. is any particular solution, which we describe how it is found in the following sections.This method applies when and are constants and is a combination of polynomials, exponentials, sines, and cosines. We guess the form of based on :Here is the smallest non-negative integer chosen so that no term in is a solution of the homogeneous equation. Substitute the guess into the ODE, match coefficients, and solve.If is a sum of such terms, find a particular solution for each term separately and add them (by superposition).This method works for any continuous and does not require constant coefficients. Given the homogeneous solutions and , we seek a particular solution of the formWe impose the condition to simplify the derivatives. Substituting into the ODE yields the systemSolving by Cramer's rule giveswhere is the Wronskian. Integrate to find and , then the particular solution isx, xxRemark 3 (Comparison).
Undetermined coefficients is simpler but limited to constant-coefficient equations with specific forms of . Variation of parameters is fully general but requires computing integrals that may not have closed-form solutions.
Theorem 4 (Existence and Uniqueness Theorem for Second Order Linear Differential Equations).
Consider the initial value problem subject to and , where , , and are continuous on an open interval that contains . There exists a unique solution over the entire interval .
Theorem 5 (Principle of Superposition).
If and are solutions of the differential equation , then any linear combination of and is also a solution.
The specific linear combination is specifically determined by the initial conditions.Definition 6 (Wronskian).
Given two solutions and of a second order linear differential equation, the Wronskian is defined as Definition 7 (Fundamental Set of Solutions).
When , and form a fundamental set of solutions, and there exists a unique solution satisfying the initial conditions. This means that the solution space of the differential equation and the space of initial conditions are isomorphic. Theorem 8 (Abel's Theorem).
If and are solutions of the second-order linear differential equation where and are continuous on an open interval , then the Wronskian is given by where is a certain constant that depends on and , but not on . Further, either is zero for all in (if ) or else is never zero in (if ).
]]></description><link>differential-equations/methods-for-second-order-differential-equations.html</link><guid isPermaLink="false">Differential Equations/Methods for Second Order Differential Equations.md</guid><pubDate>Thu, 19 Feb 2026 18:28:41 GMT</pubDate></item><item><title><![CDATA[Methods for First Order Differential Equations]]></title><description><![CDATA[We consider differential equations of the form Generally, we write a first-order differential equation in the standard form: If a first-order ODE is in a sufficiently nice form, we can employ one of several methods to ascertain its solutions. Consider a first-order differential equation in its standard form. We choose and multiply our equation by , givingNoting that , we haveWhen the integral cannot be evaluated, the general solution is where is some convenient lower bound and is a constant of integration.Sometimes we can separate terms containing from those dependent on . This allows us to write By integrating both sides, we are able to remove the derivative terms and solve for . Remark 1 (Constant solutions).
Sometimes it is easy to find a constant solution that satisfies . If we have a differential equation of the form where , , and are continuous functions in a rectangular region such that , then it is an exact differential equation. It follows that there exists a function that satisfies Equations of this form are easily solved by integrating to arrive at written in terms of an unknown function . We then differentiate and solve to determine and consequently, . The final solution is written implicitly as . It is simple to check that differentiating The solutions of the vast majority of first-order initial value problems cannot be found by analytical means. Thus, we are sometimes forced to study the solutions through numerical approximations. One of these is to draw a direction field, but it does not lend itself to quantitative computation. We investigate methods that address this shortcoming.Euler's method is an iterative algorithm that approximates how a function evolves over time based on discrete samples of . At step , we haveTake , so that it satisfies the initial condition of our ODE. Then, we integrateand solve for the constant of integration to satisfy . We continue this process, possibly infinitely, to arrive at a solution. In general,This allows us to generate a sequence . This is useful for proving the existence and uniqueness of solutions. Remark 2 (Picard's Iteration is a contraction mapping.).We would like to know when an equation has a solution given some initial condition and other solutions exist. Theorem 3 (Existence and Uniqueness for First-Order Nonlinear Equations).
Let the functions and be continuous in some rectangle defined by and containing the point . Then, in some interval contained in , there is a unique solution of the initial value problem subject to Further, the continuity of implies existence, and the continuity of implies uniqueness. Corollary 4 (Existence and Uniqueness for First-Order Linear Equations).
If the functions and are continuous on an open interval containing the point , then there exists a unique function that satisfies the differential equation for each , and that also satisfies the initial condition where is an arbitrary prescribed initial value.
Proof.
Substituting and , and applying <a data-tooltip-position="top" aria-label="^d9d47c" data-href="#^d9d47c" href="#^d9d47c" class="original-internal-link" target="_self" rel="noopener nofollow" style="display: none;">the Existence and Uniqueness Theorem</a><a data-tooltip-position="top" aria-label="^d9d47c" data-href="#^d9d47c" href="#^d9d47c" class="internal-link mathLink-internal-link" target="_self" rel="noopener nofollow">the Existence and Uniqueness Theorem</a>, we find that the continuity of and are sufficient and necessary for there to exist a unique solution.
□Definition 5 (Autonomous Differential Equation).
An autonomous differential equation is a first-order differential equation in which the independent variable does not appear explicitly. Such equations have the form <br>Definition 6 (Critical Points).
The zeros of in an <a data-tooltip-position="top" aria-label="^c8995d" data-href="#^c8995d" href="#^c8995d" class="original-internal-link" target="_self" rel="noopener nofollow" style="display: none;">Autonomous Differential Equation</a><a data-tooltip-position="top" aria-label="^c8995d" data-href="#^c8995d" href="#^c8995d" class="internal-link mathLink-internal-link" target="_self" rel="noopener nofollow">Autonomous Differential Equation</a> are called critical points. Definition 7 (Asymptotically Stable).
An equilibrium point is asymptotically stable if there exists an such that for all , the solutions that pass through approach as .
The logistic equation is of the form where is the intrinsic growth rate and is the carrying capacity.We can modify the logistic growth equation to include a threshold as follows:where and . Note that is asymptotically unstable at and asymptotically stable at and .]]></description><link>differential-equations/methods-for-first-order-differential-equations.html</link><guid isPermaLink="false">Differential Equations/Methods for First Order Differential Equations.md</guid><pubDate>Thu, 19 Feb 2026 01:18:34 GMT</pubDate></item></channel></rss>